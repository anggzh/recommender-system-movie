{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recommender System.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLwoACWiP9Dj"
      },
      "source": [
        "# Recommender System"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oksg2UGcQDWm"
      },
      "source": [
        "1. Import Basic Librariy dan File Unloading\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PohslYAEP6mZ"
      },
      "source": [
        "#import library yang dibutuhkan\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "\n",
        "#lakukan pembacaan dataset\n",
        "movie_rating_df = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/movie_rating_df.csv') #untuk menyimpan movie_rating_df.csv\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qR8LYYjUQ4MK"
      },
      "source": [
        "2. Menampilkan 5 baris teratas dan tipedata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwiYo6E2QZa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "4c32aecf-195b-4b53-978b-6670aa52f4ba"
      },
      "source": [
        "#tampilkan 5 baris teratas dari movive_rating_df\n",
        "print(movie_rating_df.head())\n",
        "\n",
        "#tampilkan info mengenai tipe data dari tiap kolom\n",
        "print(movie_rating_df.info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      tconst titleType  ... averageRating numVotes\n",
            "0  tt0000001     short  ...           5.6     1608\n",
            "1  tt0000002     short  ...           6.0      197\n",
            "2  tt0000003     short  ...           6.5     1285\n",
            "3  tt0000004     short  ...           6.1      121\n",
            "4  tt0000005     short  ...           6.1     2050\n",
            "\n",
            "[5 rows x 11 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 751614 entries, 0 to 751613\n",
            "Data columns (total 11 columns):\n",
            " #   Column          Non-Null Count   Dtype  \n",
            "---  ------          --------------   -----  \n",
            " 0   tconst          751614 non-null  object \n",
            " 1   titleType       751614 non-null  object \n",
            " 2   primaryTitle    751614 non-null  object \n",
            " 3   originalTitle   751614 non-null  object \n",
            " 4   isAdult         751614 non-null  int64  \n",
            " 5   startYear       751614 non-null  float64\n",
            " 6   endYear         16072 non-null   float64\n",
            " 7   runtimeMinutes  751614 non-null  float64\n",
            " 8   genres          486766 non-null  object \n",
            " 9   averageRating   751614 non-null  float64\n",
            " 10  numVotes        751614 non-null  int64  \n",
            "dtypes: float64(4), int64(2), object(5)\n",
            "memory usage: 63.1+ MB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6sfaUUVRA_l"
      },
      "source": [
        "3. Menambah dataframe aktor dan aktris"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBzhHNrmRiGh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "81aa9797-1562-479f-a7e5-1f62da5b1368"
      },
      "source": [
        "#Simpan actor_name.csv pada variable name_df \n",
        "name_df = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/actor_name.csv')\n",
        "\n",
        "#Tampilkan 5 baris teratas dari name_df\n",
        "print(name_df.head())\n",
        "\n",
        "#Tampilkan informasi mengenai tipe data dari tiap kolom pada name_df\n",
        "print(name_df.info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       nconst  ...                           knownForTitles\n",
            "0   nm1774132  ...  tt0417686,tt1713976,tt1891860,tt0454839\n",
            "1  nm10683464  ...                                tt7718088\n",
            "2   nm1021485  ...                                tt0168790\n",
            "3   nm6940929  ...                                tt4232168\n",
            "4   nm5764974  ...                                tt3014168\n",
            "\n",
            "[5 rows x 6 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 6 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   nconst             1000 non-null   object\n",
            " 1   primaryName        1000 non-null   object\n",
            " 2   birthYear          1000 non-null   object\n",
            " 3   deathYear          1000 non-null   object\n",
            " 4   primaryProfession  891 non-null    object\n",
            " 5   knownForTitles     1000 non-null   object\n",
            "dtypes: object(6)\n",
            "memory usage: 47.0+ KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtwKvwtrRqDF"
      },
      "source": [
        "4. Add dataframe directors dan writernim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RL48La0JSKPb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "95ce7bb8-b4af-4ece-c786-d1ebad10fb9d"
      },
      "source": [
        "#Menyimpan dataset pada variabel director_writers\n",
        "director_writers = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/directors_writers.csv')\n",
        "\n",
        "#Manampilkan 5 baris teratas\n",
        "print(director_writers.head())\n",
        "\n",
        "#Menampilkan informasi tipe data\n",
        "print(director_writers.info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      tconst  ...                                      writer_name\n",
            "0  tt0011414  ...                          John Emerson,Anita Loos\n",
            "1  tt0011890  ...     Arthur F. Goodrich,Burns Mantle,Mary Murillo\n",
            "2  tt0014341  ...  Jean C. Havez,Clyde Bruckman,Joseph A. Mitchell\n",
            "3  tt0018054  ...                                Jeanie Macpherson\n",
            "4  tt0024151  ...                 Max Miller,Wells Root,Jack Jevne\n",
            "\n",
            "[5 rows x 3 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 986 entries, 0 to 985\n",
            "Data columns (total 3 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   tconst         986 non-null    object\n",
            " 1   director_name  986 non-null    object\n",
            " 2   writer_name    986 non-null    object\n",
            "dtypes: object(3)\n",
            "memory usage: 23.2+ KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XY2VQX_fTXwl"
      },
      "source": [
        "5. Convert into list\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tgh1E08WTa29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "2d565854-170a-4eeb-d46a-b551d3109fcf"
      },
      "source": [
        "import pandas as pd\n",
        "director_writers = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/directors_writers.csv')\n",
        "\n",
        "#Mengubah director_name menjadi list\n",
        "director_writers['director_name'] = director_writers['director_name'].apply(lambda row: row.split(','))\n",
        "director_writers['writer_name'] = director_writers['writer_name'].apply(lambda row: row.split(','))\n",
        "\n",
        "#Tampilkan 5 data teratas\n",
        "print(director_writers.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      tconst  ...                                        writer_name\n",
            "0  tt0011414  ...                         [John Emerson, Anita Loos]\n",
            "1  tt0011890  ...   [Arthur F. Goodrich, Burns Mantle, Mary Murillo]\n",
            "2  tt0014341  ...  [Jean C. Havez, Clyde Bruckman, Joseph A. Mitc...\n",
            "3  tt0018054  ...                                [Jeanie Macpherson]\n",
            "4  tt0024151  ...               [Max Miller, Wells Root, Jack Jevne]\n",
            "\n",
            "[5 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7nJ7LDHVrXn"
      },
      "source": [
        "6. Update name_df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhtyM0FyVvXu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d253bdf9-7dc7-40a5-d85a-1d4d99ca4aa4"
      },
      "source": [
        "name_df = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/actor_name.csv')\n",
        "#Kita hanya akan membutuhkan kolom nconst, primaryName, dan knownForTitles\n",
        "name_df = name_df[['nconst','primaryName','knownForTitles']]\n",
        "\n",
        "#Tampilkan 5 baris teratas dari name_df\n",
        "print(name_df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       nconst          primaryName                           knownForTitles\n",
            "0   nm1774132    Nathan McLaughlin  tt0417686,tt1713976,tt1891860,tt0454839\n",
            "1  nm10683464        Bridge Andrew                                tt7718088\n",
            "2   nm1021485    Brandon Fransvaag                                tt0168790\n",
            "3   nm6940929   Erwin van der Lely                                tt4232168\n",
            "4   nm5764974  Svetlana Shypitsyna                                tt3014168\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaZSE6UFX0J2"
      },
      "source": [
        "7. Pengecekan variasi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmoM9_PCX3Iw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "89580720-65f8-446d-be76-364113062b1d"
      },
      "source": [
        "#Melakukan pengecekan variasi\n",
        "print(name_df['knownForTitles'].apply(lambda x: len(x.split(','))).unique())\n",
        "\n",
        "#Mengubah knownForTitles menjadi list of list\n",
        "name_df['knownForTitles'] = name_df['knownForTitles'].apply(lambda x: x.split(','))\n",
        "\n",
        "#Mencetak 5 baris teratas\n",
        "print(name_df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4 1 2 3]\n",
            "       nconst  ...                                knownForTitles\n",
            "0   nm1774132  ...  [tt0417686, tt1713976, tt1891860, tt0454839]\n",
            "1  nm10683464  ...                                   [tt7718088]\n",
            "2   nm1021485  ...                                   [tt0168790]\n",
            "3   nm6940929  ...                                   [tt4232168]\n",
            "4   nm5764974  ...                                   [tt3014168]\n",
            "\n",
            "[5 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZG50dgc2iAJX"
      },
      "source": [
        "8. Korespodensi 1-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8K5fht9iDuh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "c7f69eb2-2961-40a4-9779-43835daeb916"
      },
      "source": [
        "import numpy as np\n",
        "#menyiapkan bucket untuk dataframe\n",
        "df_uni = []\n",
        "\n",
        "for x in ['knownForTitles']:\n",
        "    #mengulang index dari tiap baris sampai tiap elemen dari knownForTitles\n",
        "    idx = name_df.index.repeat(name_df['knownForTitles'].str.len())\n",
        "   \n",
        "   #memecah values dari list di setiap baris dan menggabungkan nya dengan rows lain menjadi dataframe\n",
        "    df1 = pd.DataFrame({\n",
        "        x: np.concatenate(name_df[x].values)\n",
        "    })\n",
        "    \n",
        "    #mengganti index dataframe tersebut dengan idx yang sudah kita define di awal\n",
        "    df1.index = idx\n",
        "    #untuk setiap dataframe yang terbentuk, kita append ke dataframe bucket\n",
        "    df_uni.append(df1)\n",
        "    \n",
        "#menggabungkan semua dataframe menjadi satu\n",
        "df_concat = pd.concat(df_uni, axis=1)\n",
        "\n",
        "#left join dengan value dari dataframe yang awal\n",
        "unnested_df = df_concat.join(name_df.drop(['knownForTitles'], 1), how='left')\n",
        "\n",
        "#select kolom sesuai dengan dataframe awal\n",
        "unnested_df = unnested_df[name_df.columns.tolist()]\n",
        "print(unnested_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         nconst        primaryName knownForTitles\n",
            "0     nm1774132  Nathan McLaughlin      tt0417686\n",
            "0     nm1774132  Nathan McLaughlin      tt1713976\n",
            "0     nm1774132  Nathan McLaughlin      tt1891860\n",
            "0     nm1774132  Nathan McLaughlin      tt0454839\n",
            "1    nm10683464      Bridge Andrew      tt7718088\n",
            "..          ...                ...            ...\n",
            "998   nm5245804      Eliza Jenkins      tt1464058\n",
            "999   nm0948460         Greg Yolen      tt0436869\n",
            "999   nm0948460         Greg Yolen      tt0476663\n",
            "999   nm0948460         Greg Yolen      tt0109723\n",
            "999   nm0948460         Greg Yolen      tt0364484\n",
            "\n",
            "[1918 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIAtHOOsj6M6"
      },
      "source": [
        "9. Mengelompokkan primaryName menjadi list group by knownForTitles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MV5PdM5skIhv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "581b2679-9555-4529-d92a-319fec4566e7"
      },
      "source": [
        "unnested_drop = unnested_df.drop(['nconst'], axis=1)\n",
        "df_uni = []\n",
        "\n",
        "for col in ['primaryName']:\n",
        "  #agregasi kolom PrimaryName sesuai group_col yang kita define di atas\n",
        "  dfi = unnested_drop.groupby(['knownForTitles'])[col].apply(list)\n",
        "  df_uni.append(dfi)\n",
        "df_grouped = pd.concat(df_uni, axis=1).reset_index()\n",
        "df_grouped.columns = ['knownForTitles','cast_name']\n",
        "print(df_grouped)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     knownForTitles           cast_name\n",
            "0         tt0008125    [Charles Harley]\n",
            "1         tt0009706    [Charles Harley]\n",
            "2         tt0010304  [Natalie Talmadge]\n",
            "3         tt0011414  [Natalie Talmadge]\n",
            "4         tt0011890  [Natalie Talmadge]\n",
            "...             ...                 ...\n",
            "1893      tt9610496  [Stefano Baffetti]\n",
            "1894      tt9714030        [Kevin Kain]\n",
            "1895      tt9741820   [Caroline Plyler]\n",
            "1896      tt9759814     [Ethan Francis]\n",
            "1897      tt9856236     [Nuala Maguire]\n",
            "\n",
            "[1898 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqP5bk1dkX-l"
      },
      "source": [
        "10. Join Table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbtiPPococ0T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "81d26b86-0e9a-4817-b29c-7087f86cbef2"
      },
      "source": [
        "movie_rating_df = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/movie_rating_df.csv')\n",
        "\n",
        "#join antara movie table dan cast table\n",
        "base_df = pd.merge(df_grouped, movie_rating_df, left_on='knownForTitles', right_on='tconst', how='inner')\n",
        "\n",
        "#join antara base_df dengan director_writer table\n",
        "base_df = pd.merge(base_df, director_writers, left_on='tconst', right_on='tconst', how='left')\n",
        "print(base_df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  knownForTitles  ...                                        writer_name\n",
            "0      tt0011414  ...                         [John Emerson, Anita Loos]\n",
            "1      tt0011890  ...   [Arthur F. Goodrich, Burns Mantle, Mary Murillo]\n",
            "2      tt0014341  ...  [Jean C. Havez, Clyde Bruckman, Joseph A. Mitc...\n",
            "3      tt0018054  ...                                [Jeanie Macpherson]\n",
            "4      tt0024151  ...               [Max Miller, Wells Root, Jack Jevne]\n",
            "\n",
            "[5 rows x 15 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHeBWtuSq22w"
      },
      "source": [
        "11. Cleaning Table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJpqAf8Pq7P7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "c31b0a00-bc84-487a-9f94-837c3b66fee4"
      },
      "source": [
        "#Melakukan drop terhadap kolom knownForTitles\n",
        "base_drop = base_df.drop(['knownForTitles'], axis=1)\n",
        "print(base_drop.info())\n",
        "\n",
        "#Mengganti nilai NULL pada kolom genres dengan 'Unknown'\n",
        "base_drop['genres'] = base_drop['genres'].fillna('Unknown')\n",
        "\n",
        "#Melakukan perhitungan jumlah nilai NULL pada tiap kolom\n",
        "print(base_drop.isnull().sum())\n",
        "\n",
        "#Mengganti nilai NULL pada kolom dorector_name dan writer_name dengan 'Unknown'\n",
        "base_drop[['director_name','writer_name']] = base_drop[['director_name','writer_name']].fillna('unknown')\n",
        "\n",
        "#karena value kolom genres terdapat multiple values, jadi kita akan bungkus menjadi list of list\n",
        "base_drop['genres'] = base_drop['genres'].apply(lambda x: x.split(','))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1060 entries, 0 to 1059\n",
            "Data columns (total 14 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   cast_name       1060 non-null   object \n",
            " 1   tconst          1060 non-null   object \n",
            " 2   titleType       1060 non-null   object \n",
            " 3   primaryTitle    1060 non-null   object \n",
            " 4   originalTitle   1060 non-null   object \n",
            " 5   isAdult         1060 non-null   int64  \n",
            " 6   startYear       1060 non-null   float64\n",
            " 7   endYear         110 non-null    float64\n",
            " 8   runtimeMinutes  1060 non-null   float64\n",
            " 9   genres          745 non-null    object \n",
            " 10  averageRating   1060 non-null   float64\n",
            " 11  numVotes        1060 non-null   int64  \n",
            " 12  director_name   986 non-null    object \n",
            " 13  writer_name     986 non-null    object \n",
            "dtypes: float64(4), int64(2), object(8)\n",
            "memory usage: 124.2+ KB\n",
            "None\n",
            "cast_name           0\n",
            "tconst              0\n",
            "titleType           0\n",
            "primaryTitle        0\n",
            "originalTitle       0\n",
            "isAdult             0\n",
            "startYear           0\n",
            "endYear           950\n",
            "runtimeMinutes      0\n",
            "genres              0\n",
            "averageRating       0\n",
            "numVotes            0\n",
            "director_name      74\n",
            "writer_name        74\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlUh8ozgsRrX"
      },
      "source": [
        "12. Reformat"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pl1s8_n3sWxM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "13cf88e9-4688-4554-bc6f-8797b642c9b7"
      },
      "source": [
        "base_drop2 = base_drop.drop(['tconst','isAdult','endYear','originalTitle'], axis=1)\n",
        "base_drop2 = base_drop2[['primaryTitle','titleType','startYear','runtimeMinutes','genres','averageRating','numVotes','cast_name','director_name','writer_name']]\n",
        "base_drop2.columns = ['title','type','start','duration','genres','rating','votes','cast_name','director_name','writer_name']\n",
        "print(base_drop2.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                    title  ...                                        writer_name\n",
            "0         The Love Expert  ...                         [John Emerson, Anita Loos]\n",
            "1               Yes or No  ...   [Arthur F. Goodrich, Burns Mantle, Mary Murillo]\n",
            "2         Our Hospitality  ...  [Jean C. Havez, Clyde Bruckman, Joseph A. Mitc...\n",
            "3       The King of Kings  ...                                [Jeanie Macpherson]\n",
            "4  I Cover the Waterfront  ...               [Max Miller, Wells Root, Jack Jevne]\n",
            "\n",
            "[5 rows x 10 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOtMHSDFsptR"
      },
      "source": [
        "13. Klasifikasi Metadata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97N2QHhTstrS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "5ad6cc4a-0e73-48ba-eb38-2b5f488453ef"
      },
      "source": [
        "#Klasifikasi berdasar title, cast_name, genres, director_name, dan writer_name\n",
        "feature_df = base_drop2[['title','cast_name','genres','director_name','writer_name']]\n",
        "\n",
        "#Tampilkan 5 baris teratas\n",
        "print(feature_df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                    title  ...                                        writer_name\n",
            "0         The Love Expert  ...                         [John Emerson, Anita Loos]\n",
            "1               Yes or No  ...   [Arthur F. Goodrich, Burns Mantle, Mary Murillo]\n",
            "2         Our Hospitality  ...  [Jean C. Havez, Clyde Bruckman, Joseph A. Mitc...\n",
            "3       The King of Kings  ...                                [Jeanie Macpherson]\n",
            "4  I Cover the Waterfront  ...               [Max Miller, Wells Root, Jack Jevne]\n",
            "\n",
            "[5 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "431XeRXEyLdJ"
      },
      "source": [
        "14. Pertanyaan 1: Bagaimana cara membuat fungsi untuk strip spaces dari setiap row dan setiap elemennya?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opJqX3SoyKT0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "bc0c71f3-bcc8-4b10-ed54-e08e943d4ca5"
      },
      "source": [
        "def sanitize(x):\n",
        "    try:\n",
        "        #kalau cell berisi list\n",
        "        if isinstance(x, list):\n",
        "            return [i.replace(' ','').lower() for i in x]\n",
        "        #kalau cell berisi string\n",
        "        else:\n",
        "            return [x.replace(' ','').lower()]\n",
        "    except:\n",
        "        print(x)\n",
        "        \n",
        "#Kolom : cast_name, genres, writer_name, director_name        \n",
        "feature_cols = ['cast_name','genres','writer_name','director_name']\n",
        "\n",
        "#Apply function sanitize \n",
        "for col in feature_cols:\n",
        "    feature_df[col] = feature_df[col].apply(sanitize)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdRy7kP1VXWD"
      },
      "source": [
        "15. Pertanyaan 2: Bagaimana cara membuat fungsi untuk membuat metadata soup (menggabungkan semua feature menjadi 1 bagian kalimat) untuk setiap judulnya?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kOax5dcVank",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "7a745222-d1d0-4844-97d1-e57422961674"
      },
      "source": [
        "def soup_feature(x):\n",
        "\treturn ' '.join(x['cast_name']) + ' ' + ' '.join(x['genres']) + ' ' + ' '.join(x['director_name']) + ' ' + ' '.join(x['writer_name'])\n",
        "\n",
        "#membuat soup menjadi 1 kolom sendiri\n",
        "feature_df['soup'] = feature_df.apply(soup_feature, axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7Q5EcGQIUfl"
      },
      "source": [
        "16. Pertanyaan 3: Cara menyiapkan CountVectorizer (stop_words = english) dan fit dengan soup yang kita buat di atas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaKWgze2IWL5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "57412e97-460c-497f-811d-7585ca17a832"
      },
      "source": [
        "#import CountVectorizer \n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#definisikan CountVectorizer dan mengubah soup tadi menjadi bentuk vector\n",
        "count = CountVectorizer(stop_words='english')\n",
        "count_matrix = count.fit_transform(feature_df['soup'])\n",
        "\n",
        "print(count)\n",
        "print(count_matrix.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
            "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
            "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
            "                ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
            "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
            "                tokenizer=None, vocabulary=None)\n",
            "(1060, 10026)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQBJFqvJIbxO"
      },
      "source": [
        "17. Pertanyaan 4: Cara membuat model similarity antara count matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Icp8Bq1qJl1E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "4e2f86e2-805b-4022-b1e8-a5a655862dcf"
      },
      "source": [
        "#Import cosine_similarity\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "#Gunakan cosine_similarity antara count_matrix \n",
        "cosine_sim = cosine_similarity(count_matrix, count_matrix)\n",
        "\n",
        "#print hasilnya\n",
        "print(cosine_sim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.         0.15430335 0.35355339 ... 0.         0.         0.13608276]\n",
            " [0.15430335 1.         0.10910895 ... 0.         0.         0.        ]\n",
            " [0.35355339 0.10910895 1.         ... 0.         0.08703883 0.09622504]\n",
            " ...\n",
            " [0.         0.         0.         ... 1.         0.         0.        ]\n",
            " [0.         0.         0.08703883 ... 0.         1.         0.10050378]\n",
            " [0.13608276 0.         0.09622504 ... 0.         0.10050378 1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVAcSpXwLlQk"
      },
      "source": [
        "18. Pertanyaan 5: Cara membuat content based recommender system"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxe5Fr-WLlpw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "bb00cf1a-1b69-473e-9366-7ada92a374e5"
      },
      "source": [
        "indices = pd.Series(feature_df.index, index=feature_df['title']).drop_duplicates()\n",
        "\n",
        "def content_recommender(title):\n",
        "    #mendapatkan index dari judul film (title) yang disebutkan\n",
        "    idx = indices[title]\n",
        "\n",
        "    #menjadikan list dari array similarity cosine sim \n",
        "    #hint: cosine_sim[idx]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "\n",
        "    #mengurutkan film dari similarity tertinggi ke terendah\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    #untuk mendapatkan list judul dari item kedua sampe ke 11\n",
        "    sim_scores = sim_scores[1:11]\n",
        "\n",
        "    #mendapatkan index dari judul-judul yang muncul di sim_scores\n",
        "    movie_indices = [i[0] for i in sim_scores]\n",
        "\n",
        "    #dengan menggunakan iloc, kita bisa panggil balik berdasarkan index dari movie_indices\n",
        "    return base_df.iloc[movie_indices]\n",
        "\n",
        "#aplikasikan function di atas\n",
        "print(content_recommender('The Lion King'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     knownForTitles  ...                                        writer_name\n",
            "848       tt3040964  ...                    [Justin Marks, Rudyard Kipling]\n",
            "383       tt0286336  ...  [Valerie Georgeson, Colin Dann, Jenny McDade, ...\n",
            "1002      tt7222086  ...  [Akihito Tsukushi, Keigo Koyanagi, Hideyuki Ku...\n",
            "73        tt0075147  ...                                    [James Goldman]\n",
            "232       tt0119051  ...                                      [David Mamet]\n",
            "556      tt10068158  ...                                 [Akihito Tsukushi]\n",
            "9         tt0028657  ...                    [Frances Guihan, Forrest Brown]\n",
            "191       tt0107875  ...                    [Robin Lyons, George MacDonald]\n",
            "803       tt2356464  ...         [Kristina Magdalena Henn, Lea Schmidbauer]\n",
            "983       tt6270328  ...  [David Witt, John Derevlany, David Evans, Pete...\n",
            "\n",
            "[10 rows x 15 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}